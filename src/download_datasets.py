import os
from datasets import load_dataset

RAW_DIR = "data/raw"

# è¦ä¸‹è½½çš„æ•°æ®é›†ï¼šåå­— -> (HF è·¯å¾„, å­é…ç½®å)
DATASETS = {
    # "alpaca": ("tatsu-lab/alpaca", None),
    # "dolly": ("databricks/databricks-dolly-15k", None),
    # "gsm8k": ("gsm8k", "main"),             # GSM8K éœ€è¦æŒ‡å®š "main"
    # "Open-Orca": ("Open-Orca/OpenOrca", None),
    "self_instruct": ("yizhongw/self_instruct", "super_natural_instructions")
}

def show_samples(ds, name, n=3):
    print(f"\n====== {name.upper()}ï¼šå‰ {n} æ¡æ ·æœ¬ ======")
    for i in range(min(n, len(ds))):
        print(ds[i])
        print("-----------------------------------")

def main():
    os.makedirs(RAW_DIR, exist_ok=True)

    for alias, (path, subset) in DATASETS.items():
        print(f"\nğŸ“¥ æ­£åœ¨ä¸‹è½½æ•°æ®é›†ï¼š{alias} ({path}) ...")
        if subset is not None:
            dataset = load_dataset(path, subset)
        else:
            dataset = load_dataset(path)

        train_split = dataset["train"]

        # ä¿å­˜ä¸ºæœ¬åœ° jsonl
        save_path = os.path.join(RAW_DIR, f"{alias}.jsonl")
        print(f"ğŸ’¾ ä¿å­˜åˆ°ï¼š{save_path}")
        train_split.to_json(save_path)

        # æ‰“å°å‰å‡ æ¡çœ‹çœ‹ç»“æ„
        show_samples(train_split, alias, n=2)

    print("\nâœ… å…¨éƒ¨æ•°æ®é›†ä¸‹è½½ & ä¿å­˜å®Œæˆï¼")

if __name__ == "__main__":
    main()
